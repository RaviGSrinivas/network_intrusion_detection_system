{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Conventions\n",
    "<code>\n",
    "df_final = final dataframe\n",
    "df = original dataframe\n",
    "df_five = 5 variables # Use as default unless Peter's analysis suggest otherwise\n",
    "df_seven = 7 variables\n",
    "<code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2: Network Intrusion Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dwaraka\\Anaconda\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\Dwaraka\\Anaconda\\lib\\site-packages\\sklearn\\lda.py:4: DeprecationWarning: lda.LDA has been moved to discriminant_analysis.LinearDiscriminantAnalysis in 0.17 and will be removed in 0.19\n",
      "  \"in 0.17 and will be removed in 0.19\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import ShuffleSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics as mt\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.decomposition import RandomizedPCA \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.lda import LDA\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics as mt\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 82328 entries, 0 to 82331\n",
      "Data columns (total 6 columns):\n",
      "sttl                82328 non-null int64\n",
      "ct_dst_sport_ltm    82328 non-null int64\n",
      "ct_src_dport_ltm    82328 non-null int64\n",
      "swin                82328 non-null int64\n",
      "dwin                82328 non-null int64\n",
      "label               82328 non-null int64\n",
      "dtypes: int64(6)\n",
      "memory usage: 4.4 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sttl</th>\n",
       "      <th>ct_dst_sport_ltm</th>\n",
       "      <th>ct_src_dport_ltm</th>\n",
       "      <th>swin</th>\n",
       "      <th>dwin</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>82328.000000</td>\n",
       "      <td>82328.000000</td>\n",
       "      <td>82328.000000</td>\n",
       "      <td>82328.000000</td>\n",
       "      <td>82328.000000</td>\n",
       "      <td>82328.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>180.973448</td>\n",
       "      <td>3.663092</td>\n",
       "      <td>4.929040</td>\n",
       "      <td>133.453175</td>\n",
       "      <td>128.280464</td>\n",
       "      <td>0.550578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>101.512436</td>\n",
       "      <td>5.915518</td>\n",
       "      <td>8.389724</td>\n",
       "      <td>127.357276</td>\n",
       "      <td>127.491408</td>\n",
       "      <td>0.497438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>62.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>254.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>254.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>255.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               sttl  ct_dst_sport_ltm  ct_src_dport_ltm          swin  \\\n",
       "count  82328.000000      82328.000000      82328.000000  82328.000000   \n",
       "mean     180.973448          3.663092          4.929040    133.453175   \n",
       "std      101.512436          5.915518          8.389724    127.357276   \n",
       "min        0.000000          1.000000          1.000000      0.000000   \n",
       "25%       62.000000          1.000000          1.000000      0.000000   \n",
       "50%      254.000000          1.000000          1.000000    255.000000   \n",
       "75%      254.000000          3.000000          4.000000    255.000000   \n",
       "max      255.000000         38.000000         59.000000    255.000000   \n",
       "\n",
       "               dwin         label  \n",
       "count  82328.000000  82328.000000  \n",
       "mean     128.280464      0.550578  \n",
       "std      127.491408      0.497438  \n",
       "min        0.000000      0.000000  \n",
       "25%        0.000000      0.000000  \n",
       "50%      255.000000      1.000000  \n",
       "75%      255.000000      1.000000  \n",
       "max      255.000000      1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load UNSW_NB15 into a Pandas dataframe\n",
    "df = pd.read_csv('UNSW_NB15_training_set.csv')\n",
    "\n",
    "# Remove the four duplicate rows with invalid value for is_ftp_login\n",
    "df = df[df.is_ftp_login != 2]\n",
    "\n",
    "# original df_five from minilab that were selected based off results from correlation matrix as most important features.\n",
    "df_five = df[['sttl','ct_dst_sport_ltm', 'ct_src_dport_ltm', 'swin', 'dwin', 'label' ]] # \n",
    "df_five.info()\n",
    "df_five.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShuffleSplit(82328, n_iter=3, test_size=0.2, random_state=None)\n"
     ]
    }
   ],
   "source": [
    "# we want to predict the X and y data as follows for 5 feature iteration: \n",
    "if 'label' in df_five:\n",
    "    y = df_five['label'].values # get the labels we want\n",
    "    del df_five['label'] # get rid of the class label\n",
    "    X = df_five.values # use everything else to predict!\n",
    "\n",
    "    # X and y are now numpy matrices, by calling 'values' on the pandas data frames we\n",
    "    # have converted them into simple matrices to use with scikit learn\n",
    "    \n",
    "    \n",
    "# to use the cross validation object in scikit learn, we need to grab an instance\n",
    "# of the object and set it up. This object will be able to split our data into \n",
    "# training and testing splits\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n=num_instances,\n",
    "                         n_iter=num_cv_iterations,\n",
    "                         test_size  = 0.2)\n",
    "                         \n",
    "print cv_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    }
   ],
   "source": [
    "#http://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html\n",
    "#was having issue loading the data as exmaple specifies with .data/.target,\n",
    "#instead tried to load data like Peter had previously done, by assigning values and then eliminating the 'label' category.\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "\n",
    "# Data to play with\n",
    "if 'label' in df_five:\n",
    "    y = df_five['label'].values # get the labels we want\n",
    "    del df_five['label'] # get rid of the class label\n",
    "    X = df_five.values # use everything else to predict!\n",
    "\n",
    "# Binarize the output\n",
    "y = label_binarize(y, classes=[0, 1, 2])\n",
    "n_classes = y.shape[1]\n",
    "\n",
    "# Add noisy features to make the problem harder\n",
    "random_state = np.random.RandomState(0)\n",
    "n_samples, n_features = X.shape\n",
    "X = np.c_[X, random_state.randn(n_samples, 20 * n_features)]\n",
    "\n",
    "# shuffle and split training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.5,\n",
    "                                                    random_state=0)\n",
    "\n",
    "# Learn to predict each class against the other\n",
    "classifier = OneVsRestClassifier(svm.SVC(kernel='linear', probability=True,\n",
    "                                 random_state=random_state))\n",
    "y_score = classifier.fit(X_train, y_train).decision_function(X_test)\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr[2], tpr[2], color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[2])\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation:\n",
    "\n",
    "* Define and prepare your class variables. Use proper variable representations (int, float, one-hot, etc.). Use pre-processing methods (as needed) for dimensionality reduction, scaling, etc. Remove variables that are not needed/useful for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Peter\n",
    "# df_five and df_seven based of describe does not require one-hot encoding and is ready for modeling\n",
    "# First lets redo accuracy results for logistic regression on original 5 features selected based on correlation matrix from\n",
    "# from lab 1 for accuracy comparision with additional 2 features suggested by grader using logistic regression model\n",
    "# with 80/20 shuffle split cross validation to determine if we should proceed with original 5 or add additional two features for\n",
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShuffleSplit(82328, n_iter=3, test_size=0.2, random_state=None)\n"
     ]
    }
   ],
   "source": [
    "# we want to predict the X and y data as follows for 5 feature iteration: \n",
    "if 'label' in df_five:\n",
    "    y = df_five['label'].values # get the labels we want\n",
    "    del df_five['label'] # get rid of the class label\n",
    "    X = df_five.values # use everything else to predict!\n",
    "\n",
    "    # X and y are now numpy matrices, by calling 'values' on the pandas data frames we\n",
    "    # have converted them into simple matrices to use with scikit learn\n",
    "    \n",
    "    \n",
    "# to use the cross validation object in scikit learn, we need to grab an instance\n",
    "# of the object and set it up. This object will be able to split our data into \n",
    "# training and testing splits\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n=num_instances,\n",
    "                         n_iter=num_cv_iterations,\n",
    "                         test_size  = 0.2)\n",
    "                         \n",
    "print cv_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.76867485  0.76758168  0.76673145]\n",
      "Average Accuracy (5 feature set) across 3 shuffle split cross validation iterations = 0.767662658407\n"
     ]
    }
   ],
   "source": [
    "# first we create a reusable logisitic regression object\n",
    "# here we can setup the object with different learning parameters and constants\n",
    "lr_clf = LogisticRegression(penalty='l2', C=1.0, class_weight=None) # get object\n",
    "for train_indices, test_indices in cv_object:\n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    # train the reusable logisitc regression model on the training data\n",
    "    lr_clf.fit(X_train,y_train)  # train object\n",
    "    y_hat = lr_clf.predict(X_test)\n",
    "\n",
    "accuracies = cross_val_score(lr_clf, X, y=y, cv=cv_object) # this also can help with parallelism\n",
    "print(accuracies)\n",
    "print \"Average Accuracy (5 feature set) across \" + str(num_cv_iterations) + \" shuffle split cross validation iterations = \" + str(np.average(accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShuffleSplit(82328, n_iter=3, test_size=0.2, random_state=None)\n"
     ]
    }
   ],
   "source": [
    "# we want to predict the X and y data as follows for 7 feature iteration: \n",
    "if 'label' in df_seven:\n",
    "    y = df_seven['label'].values # get the labels we want\n",
    "    del df_seven['label'] # get rid of the class label\n",
    "    X = df_seven.values # use everything else to predict!\n",
    "\n",
    "    # X and y are now numpy matrices, by calling 'values' on the pandas data frames we\n",
    "    # have converted them into simple matrices to use with scikit learn\n",
    "    \n",
    "    \n",
    "# to use the cross validation object in scikit learn, we need to grab an instance\n",
    "# of the object and set it up. This object will be able to split our data into \n",
    "# training and testing splits\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n=num_instances,\n",
    "                         n_iter=num_cv_iterations,\n",
    "                         test_size  = 0.2)\n",
    "                         \n",
    "print cv_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.77280457  0.77043605  0.77620551]\n",
      "Average Accuracy (7 feature set) across 3 shuffle split cross validation iterations = 0.773148710474\n"
     ]
    }
   ],
   "source": [
    "# first we create a reusable logisitic regression object\n",
    "# here we can setup the object with different learning parameters and constants\n",
    "lr_clf = LogisticRegression(penalty='l2', C=1.0, class_weight=None) # get object\n",
    "for train_indices, test_indices in cv_object:\n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    # train the reusable logisitc regression model on the training data\n",
    "    lr_clf.fit(X_train,y_train)  # train object\n",
    "    y_hat = lr_clf.predict(X_test)\n",
    "\n",
    "accuracies = cross_val_score(lr_clf, X, y=y, cv=cv_object) # this also can help with parallelism\n",
    "print(accuracies)\n",
    "print \"Average Accuracy (7 feature set) across \" + str(num_cv_iterations) + \" shuffle split cross validation iterations = \" + str(np.average(accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the results there was negligible increase in accuracy with respect to including the additional 2 features\n",
    "requested by the grader in terms of explaining the data.  Hence we we stick with the original 5 based on correlation results\n",
    "from mini lab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Describe the final dataset that is used for classification/regression (include a description of any newly formed variables you created)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and Evaluation:\n",
    "* Choose and explain your evaluation metrics that you will use (i.e., accuracy, precision, recall, F-measure, or any metric we have discussed). Why are the measure(s) appropriate for analyzing the results of your modeling? Give a detailed explanation backing up any assertions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Randy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  Choose the method you will use for dividing your data into training and testing splits (i.e., are you using Stratified 10-fold cross validation? Why?). Explain why your chosen method is appropriate or use more than one method as appropriate. For example, if you are using time series data then you should be using continuous training and testing sets across time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ravi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  Create three different classification/regression models for each task (e.g., random forest, KNN, and SVM for task one and the same or different algorithms for task two). Two modeling techniques must be new (but the third could be SVM or logistic regression). Adjust parameters as appropriate to increase generalization performance using your chosen metric. You must investigate different parameters of the algorithms! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-1f01c2b31038>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# play with\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_five\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_five\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Dwaraka\\Anaconda\\lib\\site-packages\\pandas\\core\\generic.pyc\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   2670\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2671\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2672\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2673\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'data'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  Analyze the results using your chosen method of evaluation. Use visualizations of the results to bolster the analysis. Explain any visuals and analyze why they are interesting to someone that might use this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Team"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Discuss the advantages of each model for each classification task, if any. If there are not advantages, explain why. Is any model better than another? Is the difference significant with 95% confidence? Use proper statistical comparison methods. You must use statistical comparison techniques—be sure they are appropriate for your chosen method of validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Team or TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Which attributes from your analysis are most important? Use proper methods discussed in class to evaluate the importance of different attributes. Discuss the results and hypothesize about why certain attributes are more important than others for a given classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Team or TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment:\n",
    "* How useful is your model for interested parties (i.e., the companies or organizations that might want to use it for prediction)? How would you measure the model's value if it was used by these parties? How would your deploy your model for interested parties? What other data should be collected? How often would the model need to be updated, etc.? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In this phase, we understand that our evaluation model has met business objectives and is receiving reliable score data.  Making the model exceptionally useful for businesses & organizations seeking to protect assets from potential cyberattacks. The model’s performance and desirability rests on some identified variables being, the overall performance of the model to protect from attacks, the costs associated with attacks landed/ missed, and also “how well does the model grow?”  These factors could help a customer’s decision making process to employing an algorithmic method.  Ultimately our job would be to efficiently and effectively scale the methodology appropriately for each customer.  Interested customers would have a clear understanding of the nature of their business and the amount of protection needed for their size of an organization.  To properly deploy a model to the customer, they would need to be aware of the overhead related in performing certain algorithms, mostly being time and money.  The updating process of such a model could be continuous, either by streaming in live time by the seconds or delivered in blocks of time, such as hourly/daily/weekly.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exceptional Work:\n",
    "\n",
    "You have free reign to provide additional analyses\n",
    "\n",
    "• One idea: grid search parameters in a parallelized fashion and visualize the\n",
    "performances across attributes. Which parameters are most significant for making a\n",
    "good model for each classification algorithm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Randy and team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
